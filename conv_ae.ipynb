{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from   torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from   torchvision import datasets, transforms\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "from os import path as osp\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import os.path as osp\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor action_folder in os.listdir(test_path):\\n    action_example_folder = osp.join(test_path, action_folder)\\n\\n    for action_example in tqdm(os.listdir(action_example_folder)):\\n        if not action_example.endswith(\\'.mp4\\'):\\n            continue\\n        action_example_name = action_example.split(\\'.\\')[0]\\n\\n        write_dir = osp.join(action_example_folder, action_example_name)\\n        action_example_path = osp.join(action_example_folder, action_example)\\n\\n        if not osp.exists(write_dir):\\n            os.makedirs(write_dir)\\n\\n        run_cmd = \\'ffmpeg -loglevel panic -i %s %s\\' % (action_example_path, write_dir + \\'/image%d.png\\')\\n        os.system(run_cmd)\\n\\n\\n\\n#open csv\\nfileIn = open(\"/hdd/datasets/Moments_in_Time_Mini/validationSet.csv\", \"r\")\\n#create new csv for writing to \\nfileOut = open(\"/hdd/datasets/Moments_in_Time_Mini/validationSet_filtered.csv\", \"w\")\\nfor row in fileIn:\\n    #get string from row\\n    split = row.split(\".\")\\n    #delimit directory name from string\\n    directory = split[0]\\n    #if it exists in /hdd/datasets/Moments_in_Time_Mini/training, write to filtered csv\\n    if os.path.isdir(\"/hdd/datasets/Moments_in_Time_Mini/validation/\" + directory):\\n        #write row to trainingSet_filtered.csv\\n        fileOut.write(row)\\n    #else, skip over the row\\n    \\nfileIn.close()\\nfileOut.close()\\n'"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_path = '/hdd/datasets/Moments_in_Time_Mini/training'\n",
    "test_path = '/hdd/datasets/Moments_in_Time_Mini/validation'\n",
    "\n",
    "'''\n",
    "for action_folder in os.listdir(test_path):\n",
    "    action_example_folder = osp.join(test_path, action_folder)\n",
    "\n",
    "    for action_example in tqdm(os.listdir(action_example_folder)):\n",
    "        if not action_example.endswith('.mp4'):\n",
    "            continue\n",
    "        action_example_name = action_example.split('.')[0]\n",
    "\n",
    "        write_dir = osp.join(action_example_folder, action_example_name)\n",
    "        action_example_path = osp.join(action_example_folder, action_example)\n",
    "\n",
    "        if not osp.exists(write_dir):\n",
    "            os.makedirs(write_dir)\n",
    "\n",
    "        run_cmd = 'ffmpeg -loglevel panic -i %s %s' % (action_example_path, write_dir + '/image%d.png')\n",
    "        os.system(run_cmd)\n",
    "\n",
    "\n",
    "\n",
    "#open csv\n",
    "fileIn = open(\"/hdd/datasets/Moments_in_Time_Mini/validationSet.csv\", \"r\")\n",
    "#create new csv for writing to \n",
    "fileOut = open(\"/hdd/datasets/Moments_in_Time_Mini/validationSet_filtered.csv\", \"w\")\n",
    "for row in fileIn:\n",
    "    #get string from row\n",
    "    split = row.split(\".\")\n",
    "    #delimit directory name from string\n",
    "    directory = split[0]\n",
    "    #if it exists in /hdd/datasets/Moments_in_Time_Mini/training, write to filtered csv\n",
    "    if os.path.isdir(\"/hdd/datasets/Moments_in_Time_Mini/validation/\" + directory):\n",
    "        #write row to trainingSet_filtered.csv\n",
    "        fileOut.write(row)\n",
    "    #else, skip over the row\n",
    "    \n",
    "fileIn.close()\n",
    "fileOut.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MomentsDataset(Dataset):\n",
    "    def __init__(self, data_path):\n",
    "        self.data_path = data_path\n",
    "        self.df = pd.read_csv(self.data_path + 'trainingSet_filtered.csv', header=None)\n",
    "        self.class_to_index = {}\n",
    "        actions = [file_name.split('/')[0] for file_name in\n",
    "                list(self.df[self.df.columns[1]])]\n",
    "\n",
    "        actions = set(actions)\n",
    "\n",
    "        for i, action in enumerate(actions):\n",
    "            self.class_to_index[action] = i\n",
    "\n",
    "\n",
    "    def get_num_classes(self):\n",
    "        return len(self.class_to_index)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #print('---- df loc-----')\n",
    "        #print(self.df.iloc[idx])\n",
    "        #print('idx', idx)\n",
    "        file_loc, label, _, _ = self.df.iloc[idx]\n",
    "        #print('file loc', file_loc)\n",
    "\n",
    "        full_path = osp.join(self.data_path, 'training', file_loc)\n",
    "        dir_path = full_path.split('.')[0]\n",
    "\n",
    "        im_data = []\n",
    "        images = os.listdir(dir_path)\n",
    "        for image in images:\n",
    "            im = cv2.imread(osp.join(dir_path, image))\n",
    "            resized_image = cv2.resize(im, (128, 128))\n",
    "            #gray_im = rgb2gray(resized_image)\n",
    "\n",
    "            im_data.append(resized_image)\n",
    "\n",
    "        im_data = np.array(im_data)\n",
    "        im_data = im_data / 255.0\n",
    "        im_data = im_data[:90]\n",
    "        if len(im_data) < 90:\n",
    "            paste_im_data = np.zeros((90, 128, 128, 3))\n",
    "            paste_im_data[:len(im_data)] = im_data\n",
    "            paste_im_data[len(im_data):] = im_data[-1]\n",
    "            im_data = paste_im_data\n",
    "\n",
    "        index = self.class_to_index[label]\n",
    "\n",
    "        ret_info = {\n",
    "                'images': im_data[0],\n",
    "                'label': index\n",
    "                }\n",
    "\n",
    "        return ret_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, code_size):\n",
    "        super().__init__()\n",
    "        self.code_size = code_size\n",
    "        \n",
    "        # Encoder specification\n",
    "        self.enc_cnn_1 = nn.Conv2d(3, 6, kernel_size=5) #1, 10\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.enc_cnn_2 = nn.Conv2d(6, 16, kernel_size=5) #10, 20\n",
    "        self.enc_linear_1 = nn.Linear(16 * 29 * 29, 128) #4 * 4 * 20, 50\n",
    "        self.enc_linear_2 = nn.Linear(128, 84) #120\n",
    "        self.enc_linear_3 = nn.Linear(84, self.code_size) #50\n",
    "        \n",
    "        # Decoder specification\n",
    "        self.dec_linear_1 = nn.Linear(self.code_size, 84) #self.code_size, 160\n",
    "        self.dec_linear_2 = nn.Linear(84, IMAGE_SIZE) #160\n",
    "        \n",
    "    def forward(self, images):\n",
    "        code = self.encode(images)\n",
    "        out = self.decode(code)\n",
    "        return out, code\n",
    "    \n",
    "    def encode(self, images):\n",
    "        code = self.enc_cnn_1(images)\n",
    "        code = F.selu(F.max_pool2d(code, 2))\n",
    "        \n",
    "        code = self.enc_cnn_2(code)\n",
    "        code = F.selu(F.max_pool2d(code, 2))\n",
    "        \n",
    "        code = code.view(-1, 16*29*29) #[images.size(0), -1]\n",
    "        code = F.selu(self.enc_linear_1(code))\n",
    "        code = F.selu(self.enc_linear_2(code))\n",
    "        code = self.enc_linear_3(code)\n",
    "        return code\n",
    "    \n",
    "    def decode(self, code):\n",
    "        out = F.selu(self.dec_linear_1(code))\n",
    "        #print(out)\n",
    "        #print(out.shape())\n",
    "        out = F.sigmoid(self.dec_linear_2(out))\n",
    "        #print(out.shape())\n",
    "        out = out.view([code.size(0), 1, IMAGE_WIDTH, IMAGE_HEIGHT]) #1\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 16384\n",
    "IMAGE_WIDTH = IMAGE_HEIGHT = 128 #prev 256 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "#code_size = 20 #num_classes\n",
    "num_epochs = 1 #4\n",
    "batch_size = 129 #128\n",
    "lr = 0.002\n",
    "optimizer_cls = optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/hdd/datasets/Moments_in_Time_Mini/'\n",
    "\n",
    "#print('data set ')\n",
    "ds = MomentsDataset(dataset_path)\n",
    "\n",
    "code_size = ds.get_num_classes()\n",
    "#print(code_size)\n",
    "\n",
    "#label_count = ds.get_num_classes()\n",
    "#batch_size = 4\n",
    "#print('data loader')\n",
    "dataloader = DataLoader(ds, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "# Load data\n",
    "#train_data = datasets.MNIST('~/data/mnist/', train=True , transform=transforms.ToTensor())\n",
    "#test_data  = datasets.MNIST('~/data/mnist/', train=False, transform=transforms.ToTensor())\n",
    "#train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size, num_workers=4, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "autoencoder = AutoEncoder(code_size)\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optimizer_cls(autoencoder.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Loss: 1470990.75000\n",
      "Loss: 1520724.62500\n",
      "Loss: 1470050.25000\n",
      "Loss: 1454890.62500\n",
      "Loss: 1429405.25000\n",
      "Loss: 1422481.87500\n",
      "Loss: 1375345.00000\n",
      "Loss: 1346976.50000\n",
      "Loss: 1404835.75000\n",
      "Loss: 1330403.50000\n",
      "Loss: 1288371.25000\n",
      "Loss: 1310084.00000\n",
      "Loss: 1259814.75000\n",
      "Loss: 1364953.37500\n",
      "Loss: 1281821.62500\n",
      "Loss: 1312386.87500\n",
      "Loss: 1323010.37500\n",
      "Loss: 1530307.50000\n",
      "Loss: 1316883.12500\n",
      "Loss: 1381126.00000\n",
      "Loss: 1635762.00000\n",
      "Loss: 1382853.75000\n",
      "Loss: 1530106.62500\n",
      "Loss: 1793813.00000\n",
      "Loss: 2019838.00000\n",
      "Loss: 1649110.62500\n",
      "Loss: 1579725.75000\n",
      "Loss: 1610605.75000\n",
      "Loss: 1775383.50000\n",
      "Loss: 1568508.50000\n",
      "Loss: 1446736.62500\n",
      "Loss: 1393257.75000\n",
      "Loss: 1597792.75000\n",
      "Loss: 3028072.25000\n",
      "Loss: 2084283.62500\n",
      "Loss: 1600349.37500\n",
      "Loss: 1873995.25000\n",
      "Loss: 1621923.12500\n",
      "Loss: 1615296.00000\n",
      "Loss: 1508773.12500\n",
      "Loss: 1636216.37500\n",
      "Loss: 1708357.12500\n",
      "Loss: 1583851.00000\n",
      "Loss: 1484915.12500\n",
      "Loss: 1522714.25000\n",
      "Loss: 1639701.25000\n",
      "Loss: 1712772.87500\n",
      "Loss: 1769354.75000\n",
      "Loss: 1695296.87500\n",
      "Loss: 1555663.75000\n",
      "Loss: 1743084.50000\n",
      "Loss: 1886647.87500\n",
      "Loss: 1905961.12500\n",
      "Loss: 1606546.87500\n",
      "Loss: 1862347.00000\n",
      "Loss: 1800524.62500\n",
      "Loss: 2012776.62500\n",
      "Loss: 1685614.75000\n",
      "Loss: 1755291.00000\n",
      "Loss: 1541599.50000\n",
      "Loss: 1510353.25000\n",
      "Loss: 1656499.00000\n",
      "Loss: 1734883.62500\n",
      "Loss: 1654470.75000\n",
      "Loss: 1502690.37500\n",
      "Loss: 1634979.00000\n",
      "Loss: 1600790.62500\n",
      "Loss: 1659043.12500\n",
      "Loss: 1618787.25000\n",
      "Loss: 1831363.62500\n",
      "Loss: 1862616.00000\n",
      "Loss: 2144645.50000\n",
      "Loss: 2038509.75000\n",
      "Loss: 1973790.37500\n",
      "Loss: 2043123.87500\n",
      "Loss: 2196675.50000\n",
      "Loss: 2111619.75000\n",
      "Loss: 2187415.00000\n",
      "Loss: 2388491.00000\n",
      "Loss: 2160577.50000\n",
      "Loss: 2387594.25000\n",
      "Loss: 2495579.50000\n",
      "Loss: 2490903.00000\n",
      "Loss: 2415803.25000\n",
      "Loss: 2512376.25000\n",
      "Loss: 2657493.50000\n",
      "Loss: 2591553.50000\n",
      "Loss: 2733764.50000\n",
      "Loss: 2829641.00000\n",
      "Loss: 2717598.00000\n",
      "Loss: 2903878.00000\n",
      "Loss: 2824753.50000\n",
      "Loss: 2889381.00000\n",
      "Loss: 2926522.25000\n",
      "Loss: 2948680.50000\n",
      "Loss: 2980341.25000\n",
      "Loss: 3013147.50000\n",
      "Loss: 2955257.75000\n",
      "Loss: 3104349.50000\n",
      "Loss: 3074225.00000\n",
      "Loss: 3205656.25000\n",
      "Loss: 3112668.50000\n",
      "Loss: 3111022.00000\n",
      "Loss: 3331239.25000\n",
      "Loss: 3122244.00000\n",
      "Loss: 3347880.00000\n",
      "Loss: 3387057.25000\n",
      "Loss: 3119206.50000\n",
      "Loss: 3330907.75000\n",
      "Loss: 3457766.00000\n",
      "Loss: 3870559.75000\n",
      "Loss: 3658395.50000\n",
      "Loss: 3630017.25000\n",
      "Loss: 3805541.00000\n",
      "Loss: 3936262.50000\n",
      "Loss: 3724288.50000\n",
      "Loss: 3755758.25000\n",
      "Loss: 3952215.75000\n",
      "Loss: 3921975.00000\n",
      "Loss: 4008007.75000\n",
      "Loss: 4232991.00000\n",
      "Loss: 4531841.50000\n",
      "Loss: 4430672.50000\n",
      "Loss: 4458702.50000\n",
      "Loss: 4744390.50000\n",
      "Loss: 4503288.00000\n",
      "Loss: 4683180.50000\n",
      "Loss: 5214803.50000\n",
      "Loss: 5238095.00000\n",
      "Loss: 4844715.00000\n",
      "Loss: 5153931.00000\n",
      "Loss: 6504741.00000\n",
      "Loss: 6355646.00000\n",
      "Loss: 6635205.50000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-352-443606a5369d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m#print('before')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# train_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;31m#print(batch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m#raise ValueError()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pt/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pt/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;31m# need to call `.task_done()` because we don't use `.join()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pt/lib/python3.5/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pt/lib/python3.5/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pt/lib/python3.5/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pt/lib/python3.5/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "for epoch_i in range(N_EPOCHS):\n",
    "    for batch in dataloader:\n",
    "\n",
    "        X = batch['images']\n",
    "        labels = batch['label']\n",
    "\n",
    "        #X = X.reshape(batch_size, 3, 128, 128, 90)\n",
    "        X = X.reshape(batch_size, 3, 128, 128)\n",
    "        X = X.float()\n",
    "        predicted_labels = model(X)\n",
    "\n",
    "        labels = labels.long()\n",
    "\n",
    "        loss = criterion(predicted_labels, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print('Loss: %.5f' % (loss.data.cpu().numpy()))\n",
    "'''\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Epoch %d\" % epoch)\n",
    "    \n",
    "    #print('before')\n",
    "    for batch in dataloader:    # train_loader\n",
    "        #print(batch)\n",
    "        #raise ValueError()\n",
    "        \n",
    "        '''\n",
    "        out, code = autoencoder(Variable(batch['images'])) #images\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(out, images)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        '''\n",
    "        \n",
    "        X = batch['images']\n",
    "        labels = batch['label']\n",
    "\n",
    "        #X = X.reshape(batch_size, 3, 128, 128, 90)\n",
    "        X = X.reshape(batch_size, 3, 128, 128)\n",
    "        X = X.float()\n",
    "        #X = X[0:2097152, ...]\n",
    "        #predicted_labels = autoencoder(X) #model(X)\n",
    "        out, code = autoencoder(X) #this returns a tupe of the encoder output and decoder output\n",
    "\n",
    "        labels = labels.long()\n",
    "        \n",
    "        #optimizer.zero_grad()\n",
    "        #print(out)\n",
    "        #print(out.size())\n",
    "        #print(labels)\n",
    "        \n",
    "        loss = F.binary_cross_entropy(out, X[0:batch_size//3, ...], size_average=False) #input, target\n",
    "        #loss = loss_fn(out, labels) #images\n",
    "        #loss = criterion(predicted_labels, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print('Loss: %.5f' % (loss.data.cpu().numpy()))\n",
    "        \n",
    "    #print(\"Loss = %.3f\" % loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try reconstructing on test data\n",
    "test_image = random.choice(test_data)\n",
    "test_image = Variable(test_image.view([1, 1, IMAGE_WIDTH, IMAGE_HEIGHT]))\n",
    "test_reconst, _ = autoencoder(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.utils.save_image(test_image.data, 'orig.png')\n",
    "torchvision.utils.save_image(test_reconst.data, 'reconst.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
